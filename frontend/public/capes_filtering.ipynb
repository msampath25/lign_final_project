{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5096aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is used to filter the CAPEs data based on the department and metrics we wanted to focus on.\n",
    "# After filtration, we take the average of each of the metrics for each course over the past 5 years.\n",
    "# We wrote the filtration part of this notebook from scratch, and used ChatGPT to write the functions for the averaging part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ac7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c885da",
   "metadata": {},
   "outputs": [],
   "source": [
    "capes = pd.read_csv('capes_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90dfd85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_capes = capes.drop(['Total Enrolled in Course','Total CAPEs Given','Evalulation URL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc2c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "depts = ['BENG','CSE','DSC','ECE','LIGN','MAE','PSYC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fc13d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_capes = filtered_capes[\n",
    "    (filtered_capes['Quarter'].str[2:4].astype(int) > 18) & \n",
    "    (filtered_capes['Course'].str.split(' ').str[0].isin(depts))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31e463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_capes['Course']=filtered_capes['Course'].str.split(' - ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eddec8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SP', 'WI', 'FA', 'S3', 'S2', 'S1'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_capes['Quarter'].str[0:2].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "41de8feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_capes.to_csv('filtered_capes_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numeric_grade(grade):\n",
    "    \"\"\"\n",
    "    Extract the numerical part of a grade in the format 'B (3.03)'.\n",
    "    Returns None if the input is invalid or empty.\n",
    "    \"\"\"\n",
    "    if pd.isna(grade):\n",
    "        return None\n",
    "    match = re.search(r'\\(([\\d.]+)\\)', grade)  # Look for a number inside parentheses\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "def summarize_capes_data_with_top_professor(file_path):\n",
    "    # Load the CAPES data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure relevant columns are present\n",
    "    required_columns = [\n",
    "        \"Course\",\n",
    "        \"Instructor\",\n",
    "        \"Percentage Recommended Professor\",\n",
    "        \"Percentage Recommended Class\",\n",
    "        \"Study Hours per Week\",\n",
    "        \"Average Grade Expected\",\n",
    "        \"Average Grade Received\",\n",
    "        \"Quarter\"  # Ensure \"Quarter\" column is present\n",
    "    ]\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns in CAPES data: {missing_columns}\")\n",
    "\n",
    "    # Clean and process numerical fields\n",
    "    df[\"Percentage Recommended Class\"] = df[\"Percentage Recommended Class\"].str.rstrip('%').astype(float)\n",
    "    df[\"Percentage Recommended Professor\"] = df[\"Percentage Recommended Professor\"].str.rstrip('%').astype(float)\n",
    "    df[\"Study Hours per Week\"] = pd.to_numeric(df[\"Study Hours per Week\"], errors=\"coerce\")\n",
    "    df[\"Average Grade Expected\"] = df[\"Average Grade Expected\"].apply(extract_numeric_grade)\n",
    "    df[\"Average Grade Received\"] = df[\"Average Grade Received\"].apply(extract_numeric_grade)\n",
    "\n",
    "    # Calculate the average rating for each professor for each course\n",
    "    professor_averages = df.groupby([\"Course\", \"Instructor\"]).agg(\n",
    "        average_recommended_professor=(\"Percentage Recommended Professor\", \"mean\")\n",
    "    ).reset_index()\n",
    "\n",
    "    # Identify the top professor for each course\n",
    "    top_professors = professor_averages.loc[\n",
    "        professor_averages.groupby(\"Course\")[\"average_recommended_professor\"].idxmax()\n",
    "    ].rename(columns={\n",
    "        \"Instructor\": \"Top Professor\",\n",
    "        \"average_recommended_professor\": \"Top Professor Rating\"\n",
    "    })\n",
    "\n",
    "    # Group by unique Course and compute overall averages\n",
    "    summary = df.groupby(\"Course\").agg(\n",
    "        average_recommended_class=(\"Percentage Recommended Class\", \"mean\"),\n",
    "        average_study_hours=(\"Study Hours per Week\", \"mean\"),\n",
    "        average_grade_expected=(\"Average Grade Expected\", \"mean\"),\n",
    "        average_grade_received=(\"Average Grade Received\", \"mean\")\n",
    "    ).reset_index()\n",
    "\n",
    "    # Extract quarters without the year and aggregate unique values\n",
    "    df[\"Quarter_Only\"] = df[\"Quarter\"].str[:2]  # Extract the first two characters (e.g., \"WI\", \"FA\")\n",
    "    quarters_offered = df.groupby(\"Course\")[\"Quarter_Only\"].apply(lambda x: ', '.join(sorted(set(x)))).reset_index()\n",
    "    quarters_offered.rename(columns={\"Quarter_Only\": \"Quarters Offered\"}, inplace=True)\n",
    "\n",
    "    # Merge quarters information into the summary\n",
    "    summary = summary.merge(quarters_offered, on=\"Course\")\n",
    "\n",
    "    # Merge top professor information into the summary\n",
    "    summary = summary.merge(top_professors, on=\"Course\")\n",
    "\n",
    "    # Round numeric values for cleaner output\n",
    "    summary = summary.round(2)\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ab6c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your CAPES CSV file\n",
    "file_path = \"filtered_capes_data.csv\"\n",
    "\n",
    "# Summarize CAPES data\n",
    "summary = summarize_capes_data_with_top_professor(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a4de837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the summary\n",
    "summary.rename(columns={\"Course\":\"C\",\"average_recommended_class\": \"R\", \"average_study_hours\": \"H\",'average_grade_expected':'GE','average_grade_received':'GR','Top Professor':'P','Top Professor Rating':'PR', 'Quarters Offered':'Q'},inplace=True)\n",
    "\n",
    "summary = summary[summary['GR'].notna()]\n",
    "# Save the summarized data to a new CSV file\n",
    "summary.to_csv(\"average_capes_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8a6e603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>R</th>\n",
       "      <th>H</th>\n",
       "      <th>GE</th>\n",
       "      <th>GR</th>\n",
       "      <th>Q</th>\n",
       "      <th>P</th>\n",
       "      <th>PR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BENG 100</td>\n",
       "      <td>69.92</td>\n",
       "      <td>6.26</td>\n",
       "      <td>3.36</td>\n",
       "      <td>3.35</td>\n",
       "      <td>FA, S1, SP</td>\n",
       "      <td>Abbasi Shaghayegh</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BENG 102</td>\n",
       "      <td>68.55</td>\n",
       "      <td>6.06</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.64</td>\n",
       "      <td>SP</td>\n",
       "      <td>Engler Adam J.</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BENG 103B</td>\n",
       "      <td>74.00</td>\n",
       "      <td>9.51</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.27</td>\n",
       "      <td>SP</td>\n",
       "      <td>Fraley Stephanie I.</td>\n",
       "      <td>77.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BENG 110</td>\n",
       "      <td>79.68</td>\n",
       "      <td>6.91</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.19</td>\n",
       "      <td>FA, WI</td>\n",
       "      <td>Mc Culloch Andrew Douglas</td>\n",
       "      <td>80.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BENG 112A</td>\n",
       "      <td>93.77</td>\n",
       "      <td>6.52</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.06</td>\n",
       "      <td>WI</td>\n",
       "      <td>Valdez-Jasso Daniela</td>\n",
       "      <td>99.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>PSYC 60</td>\n",
       "      <td>89.52</td>\n",
       "      <td>5.44</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.86</td>\n",
       "      <td>FA, S1, S2, SP, WI</td>\n",
       "      <td>Lowe Angela Beth</td>\n",
       "      <td>96.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>PSYC 7</td>\n",
       "      <td>97.57</td>\n",
       "      <td>3.64</td>\n",
       "      <td>3.51</td>\n",
       "      <td>3.54</td>\n",
       "      <td>FA, S2, SP</td>\n",
       "      <td>Hanes Esther</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>PSYC 70</td>\n",
       "      <td>93.49</td>\n",
       "      <td>5.22</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.07</td>\n",
       "      <td>FA, S1, S2, SP, WI</td>\n",
       "      <td>Lowe Angela Beth</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>PSYC 71</td>\n",
       "      <td>88.72</td>\n",
       "      <td>5.92</td>\n",
       "      <td>3.29</td>\n",
       "      <td>3.17</td>\n",
       "      <td>FA, S1, SP, WI</td>\n",
       "      <td>Pilegard Celeste Cristine</td>\n",
       "      <td>98.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>PSYC 81</td>\n",
       "      <td>93.20</td>\n",
       "      <td>4.73</td>\n",
       "      <td>3.43</td>\n",
       "      <td>3.53</td>\n",
       "      <td>WI</td>\n",
       "      <td>Miller Cory T.</td>\n",
       "      <td>95.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>381 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             C      R     H    GE    GR                   Q  \\\n",
       "1     BENG 100  69.92  6.26  3.36  3.35          FA, S1, SP   \n",
       "2     BENG 102  68.55  6.06  3.71  3.64                  SP   \n",
       "3    BENG 103B  74.00  9.51  3.31  3.27                  SP   \n",
       "4     BENG 110  79.68  6.91  3.32  3.19              FA, WI   \n",
       "5    BENG 112A  93.77  6.52  3.35  3.06                  WI   \n",
       "..         ...    ...   ...   ...   ...                 ...   \n",
       "442    PSYC 60  89.52  5.44  3.20  2.86  FA, S1, S2, SP, WI   \n",
       "443     PSYC 7  97.57  3.64  3.51  3.54          FA, S2, SP   \n",
       "444    PSYC 70  93.49  5.22  3.35  3.07  FA, S1, S2, SP, WI   \n",
       "445    PSYC 71  88.72  5.92  3.29  3.17      FA, S1, SP, WI   \n",
       "446    PSYC 81  93.20  4.73  3.43  3.53                  WI   \n",
       "\n",
       "                             P      PR  \n",
       "1            Abbasi Shaghayegh  100.00  \n",
       "2               Engler Adam J.   72.00  \n",
       "3          Fraley Stephanie I.   77.12  \n",
       "4    Mc Culloch Andrew Douglas   80.54  \n",
       "5         Valdez-Jasso Daniela   99.63  \n",
       "..                         ...     ...  \n",
       "442           Lowe Angela Beth   96.92  \n",
       "443               Hanes Esther  100.00  \n",
       "444           Lowe Angela Beth  100.00  \n",
       "445  Pilegard Celeste Cristine   98.04  \n",
       "446             Miller Cory T.   95.50  \n",
       "\n",
       "[381 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
